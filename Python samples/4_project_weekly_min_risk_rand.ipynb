{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from collections import OrderedDict\n",
    "\n",
    "from pandas_datareader import data as pdr\n",
    "import fix_yahoo_finance\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "from scipy.spatial import distance\n",
    "from scipy.linalg import svd\n",
    "from sklearn.datasets import make_sparse_spd_matrix\n",
    "from sklearn.covariance import GraphLassoCV\n",
    "\n",
    "import cvxpy as cp\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pull and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = [\n",
    "    'JNJ', 'PFE', 'UNH', 'MRK', 'ABT', # health care\n",
    "    'XOM', 'CVX', 'COP', 'SLB', 'EOG', # energies\n",
    "    'BA', 'UNP', 'MMM', 'HON', 'UTX', # industrials\n",
    "    'BRK-B', 'JPM', 'BAC', 'WFC', 'C', # financial\n",
    "    'WMT', 'PG', 'KO', 'PEP', 'PM', # consumer staples\n",
    "    'AMZN', 'HD', 'MCD', 'NKE', 'SBUX', # consumer discretionary \n",
    "    'AAPL', 'MSFT', 'V', 'INTC', 'CSCO', # information technologies\n",
    "    'DWDP', 'ECL', 'APD', 'SHW', 'LYB', # materials / exlude Linde\n",
    "    'AMT', 'SPG', 'CCI', 'PLD', 'PSA', # real estate\n",
    "    'GOOGL', 'GOOG', 'VZ', 'T', 'CMCSA', 'DIS', # communication services / exclude Facebook\n",
    "    'NEE', 'DUK', 'D', 'SO', 'EXC' # utilities\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj_closing_prices(tickers, start_date, end_date):\n",
    "    all_prices = {}\n",
    "    for ticker in tickers:\n",
    "        prices = pdr.get_data_yahoo(ticker, \n",
    "            start=start_date,\n",
    "            end=end_date\n",
    "        )\n",
    "        all_prices[ticker] = prices[\"Adj Close\"]\n",
    "    \n",
    "    return pd.DataFrame(all_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = get_adj_closing_prices(tickers, datetime.datetime(2010, 12, 31), datetime.datetime(2019, 4, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log returns\n",
    "daily = np.log(1 + prices.pct_change().dropna())\n",
    "weekly = np.log(1 + prices.resample('W-FRI').last().pct_change().dropna())\n",
    "monthly = np.log(1 + prices.resample('BM').last().pct_change().dropna())\n",
    "yearly = np.log(1 + prices.resample('Y').last().pct_change().dropna())\n",
    "\n",
    "# % returns\n",
    "#daily = prices.pct_change().dropna()\n",
    "#weekly = prices.resample('W-FRI').last().pct_change().dropna()\n",
    "#monthly = prices.resample('BM').last().pct_change().dropna()\n",
    "#yearly = prices.resample('Y').last().pct_change().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SP500 annual variance\n",
    "sp500 = pdr.get_data_yahoo('^GSPC', start=datetime.datetime(2010, 12, 31), end=datetime.datetime(2019, 4, 1))\n",
    "daily_sp = np.log(1 + sp500[\"Adj Close\"].pct_change().dropna())\n",
    "\n",
    "for i in range(750,len(daily)):\n",
    "    print(daily.index[i].strftime('%m/%d/%Y'), np.mean((np.var(daily[(i-252):i])*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    return (df - df.mean(axis=0)) / df.std(axis=0) # standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize log returns\n",
    "daily_norm = normalize(daily)\n",
    "weekly_norm = normalize(weekly)\n",
    "monthly_norm = normalize(monthly)\n",
    "yearly_norm = normalize(yearly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def component_cumu_weight(data):\n",
    "    _, s, _ = svd(np.array(data))\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(1 + np.arange(s.shape[0]), 100 * np.cumsum(s**2) / np.sum(s**2))\n",
    "    plt.xlabel('Number of factors')\n",
    "    plt.ylabel('Explained variance (%)')\n",
    "    plt.savefig('factor_weight.png', bbox_inches='tight')\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "component_cumu_weight(monthly_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12, 30)\n",
    "\n",
    "def plot_pca(data, k): # k is number of most important components\n",
    "    U, s, Vh = svd(np.array(data))\n",
    "\n",
    "    x = np.arange(len(data.columns))\n",
    "    width = 0.15\n",
    "    \n",
    "    plt.figure()\n",
    "    for i in range(k):\n",
    "        plt.subplot(k, 1, i+1)\n",
    "        plt.bar(x + (-(k-1)/2 + i) * width, Vh[i,:], width,\n",
    "            label='Component {} ({:.1f}%)'.format(i, 100 * s[i]**2 / np.sum(s**2)))\n",
    "        third = daily.columns[Vh[i,:]**2 >= np.percentile(Vh[i,:]**2, 100 * 2 / 3)]\n",
    "        \n",
    "        # print('[Component {}] {}'.format(i, ', '.join(list(third))))\n",
    "        \n",
    "        plt.xticks(x, data.columns, rotation=90)\n",
    "        plt.title('Loading vectors')\n",
    "        plt.legend()\n",
    "        plt.savefig('pca_loading.png', bbox_inches='tight')\n",
    "        \n",
    "        # print(Vh[i,:])\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_pca(daily_norm, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_pca(weekly_norm, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_pca(monthly_norm, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_pca(yearly_norm, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Inverse Covariance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_inv_cov_mat(data, size):\n",
    "    # model = GraphLassoCV(alphas=list(np.arange(0.65,2,1)),cv=10,max_iter=5000) # forced sparsity\n",
    "    model = GraphLassoCV(alphas=10,cv=5,max_iter=5000,mode='cd')\n",
    "    model.fit(data)\n",
    "    inv_mat = pd.DataFrame(model.precision_)\n",
    "    inv_mat.columns = data.columns\n",
    "    g = model.precision_\n",
    "    #g = np.zeros((size, size))\n",
    "    #g[model.precision_>0]=0.5\n",
    "    #g[model.precision_<0]=-0.5\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(g, interpolation=\"nearest\",\n",
    "           vmax=1, vmin=-1, \n",
    "           cmap=plt.cm.RdBu_r)\n",
    "    x_ticks = plt.xticks(range(len(data.columns)), data.columns, rotation=90)\n",
    "    y_ticks = plt.yticks(range(len(data.columns)), data.columns)\n",
    "    plt.title('Robust Inverse Covariance')\n",
    "    plt.savefig('inv_full.png', bbox_inches='tight')\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_cov = np.cov(np.array(daily_norm.T))\n",
    "emp_pre = np.linalg.inv(emp_cov)\n",
    "g = emp_pre\n",
    "#g = np.zeros((56, 56))\n",
    "#g[emp_pre>0]=0.5\n",
    "#g[emp_pre<0]=-0.5\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(g, interpolation=\"nearest\",\n",
    "        vmax=1, vmin=-1, \n",
    "        cmap=plt.cm.RdBu_r)\n",
    "x_ticks = plt.xticks(range(len(daily_norm.columns)), daily_norm.columns, rotation=90)\n",
    "y_ticks = plt.yticks(range(len(daily_norm.columns)), daily_norm.columns)\n",
    "plt.title('Emp Inverse Covariance')\n",
    "plt.savefig('inv_emp.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inv_cov_mat(daily_norm, 56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inv_cov_mat(weekly_norm, 56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_inv_cov_mat(monthly_norm, 56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_selection(data):\n",
    "\n",
    "    model = GraphLassoCV(alphas=20,max_iter=5000,cv=10)\n",
    "    model.fit(data)\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.semilogx(model.cv_alphas_[0:(len(model.grid_scores_))], \n",
    "         np.mean(model.grid_scores_[0:(len(model.grid_scores_))],axis=1),\n",
    "         'o-')\n",
    "    plt.axvline(model.alpha_, color='.5')\n",
    "    plt.title('Model selection')\n",
    "    plt.ylabel('Cross-validation Score')\n",
    "    plt.xlabel('alpha')\n",
    "    plt.savefig('cv_score.png', bbox_inches='tight')\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpha_selection(daily_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#alpha_selection(weekly_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpha_selection(monthly_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean-Variance Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_expected_daily_returns(df):\n",
    "    return np.array(df.mean())\n",
    "\n",
    "def compute_daily_covariance_matrix(df):\n",
    "    return np.cov(np.array(df.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_portfolio_expected_return(return_vector, weights):\n",
    "    return return_vector.T.dot(weights)\n",
    "\n",
    "def compute_portfolio_variance(covariance_matrix, weights):\n",
    "    return weights.T.dot(covariance_matrix).dot(weights)\n",
    "\n",
    "def compute_portfolio_std(covariance_matrix, weights):\n",
    "    return np.sqrt(compute_portfolio_variance(covariance_matrix, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "target_return = 0.07\n",
    "\n",
    "def min_risk_portfolio(expected_returns, covariance_matrix, target_return):\n",
    "    n = expected_returns.shape[0]\n",
    "\n",
    "    w = cp.Variable(n)  # Portfolio allocation vector\n",
    "    ret = expected_returns.T * w\n",
    "    risk = cp.quad_form(w, covariance_matrix)\n",
    "    target_ret = cp.Parameter()\n",
    "    target_ret.value = target_return\n",
    "    prob = cp.Problem(cp.Minimize(risk), # Restricting to long-only portfolio\n",
    "                    [ret == target_ret, # match target_return\n",
    "                    cp.sum(w) == 1, # sum of weights in portfolios sum to 1.\n",
    "                    w >= 0])\n",
    "    prob.solve()\n",
    "    \n",
    "    if prob.status == 'optimal':\n",
    "        return w.value\n",
    "    else:\n",
    "        return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def efficient_frontier(expected_returns, covariance_matrix):\n",
    "\n",
    "    min_return = np.min(expected_returns)\n",
    "    max_return = np.max(expected_returns)\n",
    "    \n",
    "    target_returns = np.linspace(min_return, max_return, num=200)\n",
    "    \n",
    "    portfolio_weights = []\n",
    "    \n",
    "    for tr in target_returns:\n",
    "        result = min_risk_portfolio(expected_returns, covariance_matrix, tr)\n",
    "        # only add results if optimization was successful\n",
    "        if result is not None:\n",
    "            weights = result\n",
    "            portfolio_weights.append(weights)\n",
    "\n",
    "    return portfolio_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_variance_portfolio(covariance_matrix, portfolio_weights):\n",
    "    \n",
    "    portfolio_stds = []\n",
    "    \n",
    "    for i in portfolio_weights:\n",
    "        portfolio_stds.append(compute_portfolio_std(covariance_matrix, i))\n",
    "        \n",
    "    index = np.argmin(portfolio_stds)\n",
    "    \n",
    "    return portfolio_weights[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_free_rate = 0.026\n",
    "\n",
    "def max_sharpe_portfolio(expected_returns, covariance_matrix, risk_free_rate, portfolio_weights):\n",
    "    \n",
    "    portfolio_stds = []\n",
    "    returns = []\n",
    "    for i in portfolio_weights:\n",
    "        portfolio_stds.append(compute_portfolio_std(covariance_matrix, i))\n",
    "        returns.append(np.dot(expected_returns, i))\n",
    "    \n",
    "    sharpe_ratios = (np.array(returns) - risk_free_rate) / np.array(portfolio_stds)\n",
    "    index = np.argmax(sharpe_ratios)\n",
    "    return sharpe_ratios[index], portfolio_weights[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ************************\n",
    "# input must be daily data\n",
    "# ************************\n",
    "\n",
    "def emp_portfolio_sim(duration, rebal_freq, data):\n",
    "\n",
    "    returns = []\n",
    "    turn_over = []\n",
    "\n",
    "    for i in range(duration-1):\n",
    "    \n",
    "        if i != 0:\n",
    "            last_weights = optimal_weights\n",
    "    \n",
    "        end_d = rand_end - (duration - i) * rebal_freq\n",
    "        start_d = end_d - 252\n",
    "        \n",
    "        exp_return = compute_expected_daily_returns(np.exp(data[start_d:end_d]))\n",
    "        \n",
    "        annual_return = np.power(exp_return, 252) - 1\n",
    "   \n",
    "        cov = compute_daily_covariance_matrix(data[start_d:end_d])\n",
    "        \n",
    "        optimal_weights = min_risk_portfolio(annual_return, cov*252, target_return)\n",
    "        \n",
    "        #portfolio_weights = efficient_frontier(annual_return, cov*252)\n",
    "        #sharpe_ratio, optimal_weights = max_sharpe_portfolio(\n",
    "        #    annual_return, cov*252, risk_free_rate, portfolio_weights)\n",
    "        \n",
    "        #portfolio_weights = efficient_frontier(annual_return, cov*252)\n",
    "        #optimal_weights = min_variance_portfolio(cov*252, portfolio_weights)\n",
    "    \n",
    "        real_return = np.exp(np.sum(daily[end_d:(end_d+rebal_freq)]))-1\n",
    "    \n",
    "        if i != 0:\n",
    "            turn_over.append(distance.cityblock(optimal_weights, last_weights))\n",
    "\n",
    "        returns.append(np.dot(optimal_weights, real_return))\n",
    "\n",
    "    return returns, turn_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ************************\n",
    "# input must be daily data\n",
    "# ************************\n",
    "\n",
    "def robust_portfolio_sim(duration, rebal_freq, data):\n",
    "\n",
    "    returns = []\n",
    "    turn_over = []\n",
    "\n",
    "    for i in range(duration-1):\n",
    "    \n",
    "        if i != 0:\n",
    "            last_weights = optimal_weights\n",
    "    \n",
    "        end_d = rand_end - (duration - i) * rebal_freq\n",
    "        start_d = end_d - 252\n",
    "        \n",
    "        exp_return = compute_expected_daily_returns(np.exp(data[start_d:end_d]))\n",
    "        \n",
    "        annual_return = np.power(exp_return, 252) - 1\n",
    "        \n",
    "        # sparse cov matrix estimate\n",
    "        model = GraphLassoCV(alphas=10,cv=5,max_iter=5000,mode='cd')\n",
    "        model.fit(data[start_d:end_d])\n",
    "        cov = model.covariance_\n",
    "        \n",
    "        optimal_weights = min_risk_portfolio(annual_return, cov*252, target_return)\n",
    "        \n",
    "        #portfolio_weights = efficient_frontier(annual_return, cov*252)\n",
    "        #sharpe_ratio, optimal_weights = max_sharpe_portfolio(\n",
    "        #    annual_return, cov*252, risk_free_rate, portfolio_weights)\n",
    "        \n",
    "        #portfolio_weights = efficient_frontier(annual_return, cov*252)\n",
    "        #optimal_weights = min_variance_portfolio(cov*252, portfolio_weights)\n",
    "    \n",
    "        real_return = np.exp(np.sum(daily[end_d:(end_d+rebal_freq)]))-1\n",
    "    \n",
    "        if i != 0:\n",
    "            turn_over.append(distance.cityblock(optimal_weights, last_weights))\n",
    "\n",
    "        returns.append(np.dot(optimal_weights, real_return))\n",
    "\n",
    "    return returns, turn_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_perf(emp_return, robust_return, emp_turn_over, robust_turn_over):\n",
    "\n",
    "    total_emp_return = 1\n",
    "    for i in emp_return:\n",
    "        total_emp_return *= 1 + i\n",
    "\n",
    "    total_robust_return = 1\n",
    "    for i in robust_return:\n",
    "        total_robust_return *= 1 + i\n",
    "    \n",
    "    print(\"{0:15}\".format(\"Total Return\"),\n",
    "          \"{0:10.6f}%\".format((total_emp_return-1)*100), \"{0:10.6f}%\".format((total_robust_return-1)*100))\n",
    "    print(\"{0:15}\".format(\"Mean Return\"),\n",
    "          \"{0:10.6f}%\".format(np.mean(emp_return)*100), \"{0:10.6f}%\".format(np.mean(robust_return)*100))\n",
    "    print(\"{0:15}\".format(\"Return Var\"),\n",
    "          \"{0:10.6f}%\".format(np.var(emp_return)*100), \"{0:10.6f}%\".format(np.var(robust_return)*100))    \n",
    "\n",
    "    print(\"{0:15}\".format(\"Total TO\"),\n",
    "          \"{0:10.6f}%\".format(np.sum(emp_turn_over)*100), \"{0:10.6f}%\".format(np.sum(robust_turn_over)*100))\n",
    "    print(\"{0:15}\".format(\"Max TO\"),\n",
    "          \"{0:10.6f}%\".format(np.max(emp_turn_over)*100), \"{0:10.6f}%\".format(np.max(robust_turn_over)*100))\n",
    "    print(\"{0:15}\".format(\"Mean TO\"),\n",
    "          \"{0:10.6f}%\".format(np.mean(emp_turn_over)*100), \"{0:10.6f}%\".format(np.mean(robust_turn_over)*100))\n",
    "    print(\"{0:15}\".format(\"TO Var\"),\n",
    "          \"{0:10.6f}%\".format(np.var(emp_turn_over)*100), \"{0:10.6f}%\".format(np.var(robust_turn_over)*100))\n",
    "    \n",
    "    return (total_emp_return-1)*100, (total_robust_return-1)*100, \n",
    "    np.mean(emp_return)*100, np.mean(robust_return)*100, \n",
    "    np.var(emp_return)*100, np.var(robust_return)*100, \n",
    "    np.sum(emp_turn_over)*100, np.sum(robust_turn_over)*100, \n",
    "    np.max(emp_turn_over)*100, np.max(robust_turn_over)*100, \n",
    "    np.mean(emp_turn_over)*100, np.mean(robust_turn_over)*100, \n",
    "    np.var(emp_turn_over)*100, np.var(robust_turn_over)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 40\n",
    "rebal_freq = 5\n",
    "trials = 30\n",
    "\n",
    "for i in range(trials):\n",
    "    rand_end = random.randint(1000,len(daily))\n",
    "    print(daily.index[rand_end].strftime('%m/%d/%Y'))\n",
    "    emp_return, emp_turn_over = emp_portfolio_sim(duration,rebal_freq,daily)\n",
    "    robust_return, robust_turn_over = robust_portfolio_sim(duration,rebal_freq,daily)\n",
    "    print_perf(emp_return, robust_return, emp_turn_over, robust_turn_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 40\n",
    "rebal_freq = 10\n",
    "trials = 30\n",
    "\n",
    "for i in range(trials):\n",
    "    rand_end = random.randint(1000,len(daily))\n",
    "    print(daily.index[rand_end].strftime('%m/%d/%Y'))\n",
    "    emp_return, emp_turn_over = emp_portfolio_sim(duration,rebal_freq,daily)\n",
    "    robust_return, robust_turn_over = robust_portfolio_sim(duration,rebal_freq,daily)\n",
    "    print_perf(emp_return, robust_return, emp_turn_over, robust_turn_over)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
